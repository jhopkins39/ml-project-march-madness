<html>
  <body style="background-color:gray;">
    <h1 style="color:white; text-align:center;">CS 4641: March Madness Final Four Predictor</h1>
    <h2 style="color:white; text-decoration:underline;"> Project Presentation </h2>
    <iframe width="420" height="315"
src="https://www.youtube.com/embed/q3qS-BMO7Oo">
</iframe>
    <p style="color:white;">
        <a href="https://docs.google.com/spreadsheets/d/1ehO8z303lfPHKGtzt8DhDcydGc4Z8EzF/edit?usp=sharing&ouid=111484595320655734881&rtpof=true&sd=true">Project Timeline</a>
    </p>
    
    <p style="color:white;">
      <a href="https://github.com/jhopkins39/ml-project-march-madness">Github Link</a>
    </p>
    
    
    
    <h2 style="color:white; text-decoration:underline"> Background</h2>
        <p style="color:white;"> In many people’s opinions college basketball is the greatest sport: the kids
          fighting to win pride for their teammates in school, the unpredictability of who's going to win, 
          and of course the annual culmination of all the work they put in with the March Madness tournament.
          Part of the fun of the tournament is bracket challenges that every fan competes in. The 68 teams 
          that make the tournament are ranked and play in a bracket style tournament until one is left.  
          People compete against their friends to try to guess the winners of the tournament or at least 
          guess more than the friends.
        </p>
    <h2 style="color:white; text-decoration:underline"> Dataset Explantaion </h2>
        <p style="color:white;"> Our data set, which we have downloaded from Kaggle, includes many important
          features which describe a team.  It has the experience of the team by information such as how many
          of the players have played in a tournament before, their record, the strength of schedule, the NCAA
          ranking, the conference they play in, the point differential, the points allowed, the points scored,
          and many other basketball statistics. 
          <br>
            <a href="https://www.kaggle.com/c/march-machine-learning-mania-2017/data" target="_blank"> Check out the datasets
              here. </a>
        </p>
    <h2 style="color:white; text-decoration:underline"> Problem Definition </h2>
        <p style="color:white;"> The goal of our project is to predict the final four teams of the NCAA men’s 
          march madness tournament.  This could be very useful for people trying to beat out their friends in
          bracket challenges everywhere.
        </p>
    <h2 style="color:white; text-decoration:underline"> Methods </h2>
      <p style="color:white;"> Right now there are a couple different methods we are looking at. The first method we are going to try is a logistic regression on the the team's seed in the tournament. It finds the probability on whether or not a team makes it to the final four based on their starting seed. We were also thinking about doing a random forest model (when we learn more hopefully) and even a neural net to give us the teams who will  prevail.
      </p>
      <h4 style="color:white;"> Data Preprocessing </h4>
      <p style="color:white;">
        All of the data preprocessing was done using Pandas DataFrames. First, we created a wrapper class for 
        reading in and parsing the various csv files provided by Kaggle. The wrapper class allowed us to modularize 
        data processing and extract useful statistics. Among its functionalities are the ability to specify what data 
        columns the user would want and from which part of the season they want the data from: regular season or tournament 
        season. We also mapped the teams' id to their seed for the season in a dictionary for ease of access and determined 
        the final four participants of the season tourney by searching through the tourney game data.
        <br>
        Our dataset also contains some string inputs for the location of the winner of each game in the regular and tourney 
        seasons: 'H' for home, 'A' for away, and 'N' for neutral. However, most models don't take kindly to string inputs, so 
        we replaced them with the following discrete values: '1' for home, '-1' for away, and '0' for neutral. In addition, we 
        extracted the integers from the seeds in order for them to be valid inputs for a logistic regression model. This does 
        have the side effect of making them region independent, although we believe that to be a minor factor.
        <br>
        Finally, we decided against doing any feature selection since we are currently only working with the compact data. 
        The compact data only contains six features relevant to each game, with two of them being the ids of the winning 
        and losing team.
      </p>
      
      <p style="color:white;"> 
        
      </p>
    <h2 style="color:white; text-decoration:underline"> Results and Discussion </h2>
    <h3 style="color:white;"> Logistic Regression </h3>
    <p style="color:white;"> 
      For the final project, in addition to training other models, we improved our Logistic Regression model. Instead of using just the seed data, we transformed our entire dataset based on every game played to a dataset indexed by the team and the year. The data represents each team’s averages during the season. The data is separated by winning and losing averages and includes their record. From this information, we train our model with 2003-2015 data to predict 2016 data. Instead of narrowing down the teams to a field of 64, we are trying to predict the final four from the entire D1 college basketball field. This goal creates a problematic situation because there are not many true positives to train on and then estimate. Currently, our model returns one team that it believes will make the final four. This result presents a false positive rate of 0%, which is fantastic. However, it misses the other three teams. To help predict more teams, you can look at the internal probabilities the model creates that each testing data point has of being classified either way. If you look at the eight teams with the highest likelihood of being ranked a final 4 team, 2 of them make the final 4. This outcome is incredible, in our opinion. Going from 341 teams to 4 is tough, and if we can pick eight teams and say that 2 of them will be in the last four standing, that is incredibly powerful. Especially when some of the other options of the eight do not even make the tournament or, from visual inspection, seem unlikely. This can be seen from the output of the logistic regression model our code runs: 

    </p>
    <h4 style="color:white;"> Metrics </h4>
    <p style="color:white;">
      We got an accuracy of 94% for our regression model. Although, this accuracy is based on teams not making it to 
      the final four, it gives a good reflection of the teams that eventually made it to the final stage. The testing data had
      68 teams and our model predicted the correct outcome for 64 of them. Even though we got a decent accuracy, we would like to 
      improve upon it and in the future we plan to implement more of classification algorithms like Gausian Mixture Models(GMM) and 
      Decision Trees.
    </p>
    <h3 style="color:white;"> Neural Network </h3>
    <p style="color:white;">
        Using the preprocessed data mentioned above, we trained a neural network in PyTorch to try and predict the probability that a team would end up in the 
        final four given its regular game stats. We ahd 30 input features and decided to have two hidden layers: one with 60 neurons and another with 24. The 
        output of the last hidden layer is then condensed into a single node with a sigmoid function to convert the output to a probability. We trained this 
        neural network with the Adam optimizer (1e-4 learning rate) and binary cross entropy loss. We trained the model for 100 epochs with a batch size of 64. 
        While we did try a learning rate of 1e-3 and batch sizes of 32 and 128, these values often led to an unstable loss graph, so we ended up settling on 
        the hyperparameter values mentioned above. For the output, we decided that a probability > 0.5 would be classified as 1 and <= 0.5 as 0. Due to the 
        the unbalanced nature of the data, we decided to measure the accuracy as balanced accuracy instead of raw accuracy as it takes the sizes of each class into 
        account.
        <br>
        Another problem for this current model implementation was that it tended to collapse and output 0 for all inputs. Since each year only had 4 final four 
        teams, the data was skewed to label 0 (non final four teams). In order to resolve this issue, we decided to utilize a custom loss function based on MSE 
        loss that reduced the influence of the MSE loss against 0 labels by a certain factor. This new hyperparameter was called zero_weight. We tested values 
        of 0.01, 0.05, 0.10, 0.25, and 0.50 for zero_weight and found that zero_weight=0.10 performed the best. Values less than 0.10 penalized the loss too 
        much, resulting in the model overpredicting 1s, and values greater than 0.10 didn't seem to penalize the loss enough.
        <br>
        <br>
        <center><img src="https://user-images.githubusercontent.com/99891372/165207500-20fc5274-f8d2-4599-92f5-4990a3ca1904.png" alt = "Neural Network Curve" height="355" width="1025"></center>
        <br>
        <br>
        One other hyperparameter we tuned after training was the threshold. While we initially decided on the arbitrary value of 0.5, we ran the train and test 
        datasets through the model with different thresholds to see if the prediction accuracy would be any better. In order to have an effective model, we had 
        to balance precision and recall to try and get the model to correctly identify the final four teams without overclassifying class 1. A decent threshold 
        for the probability seems to be in the 0.5 to 0.7 range. However, the low F1 score indicates that this type of model may not be the best for this kind 
        of task. In the end, we did manage to classify 3 of the 4 final four teams correctly, but the model also ended up classifying teams that did not make 
        the final four as ones that did.
        <br>
        <br>
        <center><img src="https://user-images.githubusercontent.com/99891372/165208229-a7327b6f-799c-4330-af06-e37b60905c31.png" alt = "Neural Network Thresholds" height="763" width="506"></center>
    </p>
    <h2 style="color:white; text-decoration:underline"> References </h2>
    <p style="color:white;">
      <ul style="color:white;">
        <li> [1] A. McCabe and  J. Trevathan, "Artificial Intelligence in Sports Prediction," <i>Fifth International Conference on Information Technology</i>, pp. 1194-1197, 2008</li>
        <li> [2] R. Bunker, and T. Susnjak, "The Application of Machine Learning Techniques for Predicting Results in Team Sport: A Review,", <i>arXiv</i>, 2019</li>
        <li> [3] M. Haghighat, N. Nourafza, and H. Rastegari, "A Review of Data Mining Techniques for Result Prediction," <i>Advances in Computer Science</i>, vol. 5, pp. 6, 2013</li>
        <li> [4] H. Ji, Y. Li, A. Boudion, and E. O'Saben, "March Madness Prediction - CPP". from https://www.cpp.edu/~hji/assets/publications/MarchMadness_C/MarchMadnessPrediction.pdf </li>
        <li> [5] A. Maszczyk, , A. Gołaś, P. Pietraszewski, R. Roczniok, A. Zając, and A. Stanula, "Application of neural and regression models in sports results prediction." <i>Procedia - Social and Behavioral Sciences.</i>, 2014</li>
        <li> [6] scikit-learn developers. (n.d.). Sklearn.linear_model.logisticregression. scikit. Retrieved April 5, 2022, from https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic+regression#sklearn.linear_model.LogisticRegression 
    </ul>
    </p>
  </body>
</html>
